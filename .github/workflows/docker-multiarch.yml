name: Build and Push Multi-Arch Docker Image

on:
  workflow_dispatch:
    inputs:
      model_name:
        description: 'Embedding model name (e.g. sentence-transformers/all-MiniLM-L6-v2)'
        required: true
        default: 'sentence-transformers/all-MiniLM-L6-v2'
      image_tag:
        description: 'Docker image tag (e.g. latest, v1.0.0)'
        required: true
        default: 'latest'
      tei_version:
        description: 'TEI version (e.g. 1.8.3, 1.5)'
        required: true
        default: '1.8.3'
      device_type:
        description: 'Device type for TEI base image'
        required: true
        default: 'cpu'
        type: choice
        options:
          - cpu
          - gpu
          - turing
          - ampere80
          - ampere86
          - hopper
      model_source:
        description: 'Model download source'
        required: true
        default: 'huggingface'
        type: choice
        options:
          - huggingface
          - modelscope

jobs:
  build-and-push:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set TEI base image
        id: set-base-image
        run: |
          DEVICE_TYPE="${{ github.event.inputs.device_type }}"
          TEI_VERSION="${{ github.event.inputs.tei_version }}"
          
          # 根据设备类型构建基础镜像名称
          case "${DEVICE_TYPE}" in
            cpu)
              BASE_IMAGE="ghcr.io/huggingface/text-embeddings-inference:cpu-${TEI_VERSION}"
              ;;
            gpu)
              BASE_IMAGE="ghcr.io/huggingface/text-embeddings-inference:${TEI_VERSION}"
              ;;
            turing)
              BASE_IMAGE="ghcr.io/huggingface/text-embeddings-inference:turing-${TEI_VERSION}"
              ;;
            ampere80)
              BASE_IMAGE="ghcr.io/huggingface/text-embeddings-inference:80-${TEI_VERSION}"
              ;;
            ampere86)
              BASE_IMAGE="ghcr.io/huggingface/text-embeddings-inference:86-${TEI_VERSION}"
              ;;
            hopper)
              BASE_IMAGE="ghcr.io/huggingface/text-embeddings-inference:hopper-${TEI_VERSION}"
              ;;
            *)
              BASE_IMAGE="ghcr.io/huggingface/text-embeddings-inference:cpu-${TEI_VERSION}"
              ;;
          esac
          
          echo "base_image=${BASE_IMAGE}" >> $GITHUB_OUTPUT
          echo "Using base image: ${BASE_IMAGE}"

      - name: Build and push multi-arch image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          platforms: linux/amd64
          push: true
          tags: ghcr.io/${{ github.repository }}:${{ github.event.inputs.image_tag }}
          build-args: |
            BASE_IMAGE=${{ steps.set-base-image.outputs.base_image }}
            MODEL_ID=${{ github.event.inputs.model_name }}
            MODEL_SOURCE=${{ github.event.inputs.model_source }}
          
      - name: Image digest
        run: |
          echo "Image pushed: ghcr.io/${{ github.repository }}:${{ github.event.inputs.image_tag }}"
          echo "Base image: ${{ steps.set-base-image.outputs.base_image }}"
          echo "Model: ${{ github.event.inputs.model_name }}"
          echo "Model source: ${{ github.event.inputs.model_source }}"

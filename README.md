# embedding-images

åŸºäº [Hugging Face Text Embeddings Inference (TEI)](https://github.com/huggingface/text-embeddings-inference) çš„æ–‡æœ¬åµŒå…¥æœåŠ¡é•œåƒã€‚

## ç‰¹æ€§

- ğŸš€ é«˜æ€§èƒ½ï¼šåŸºäº Rust å®ç°ï¼Œæ”¯æŒåŠ¨æ€æ‰¹å¤„ç†
- ğŸ”Œ API å…¼å®¹ï¼šæ”¯æŒ OpenAI å…¼å®¹çš„ `/v1/embeddings` æ¥å£
- ğŸ“¦ å¼€ç®±å³ç”¨ï¼šæ— éœ€ç¼–å†™ä»£ç ï¼Œç›´æ¥ä½¿ç”¨

## æ„å»ºé•œåƒ

### CPU ç‰ˆæœ¬
```bash
docker build -t embedding-service:cpu .
```

### GPU ç‰ˆæœ¬ (CUDA)
```bash
docker build --build-arg BASE_IMAGE=ghcr.io/huggingface/text-embeddings-inference:1.5 -t embedding-service:gpu .
```

### ä½¿ç”¨å…¶ä»–æ¨¡å‹
```bash
docker build --build-arg MODEL_ID=BAAI/bge-small-en-v1.5 -t embedding-service:bge .
```

## è¿è¡Œå®¹å™¨

### CPU è¿è¡Œ
```bash
docker run -p 8000:8000 embedding-service:cpu
```

### GPU è¿è¡Œ
```bash
docker run --gpus all -p 8000:8000 embedding-service:gpu
```

### ä½¿ç”¨å¤–éƒ¨æ¨¡å‹ï¼ˆä¸é¢„ä¸‹è½½åˆ°é•œåƒï¼‰
```bash
docker run -p 8000:8000 \
  -v ~/.cache/huggingface:/data \
  ghcr.io/huggingface/text-embeddings-inference:cpu-1.5 \
  --model-id sentence-transformers/all-MiniLM-L6-v2 \
  --port 8000
```

## API ä½¿ç”¨

### å¥åº·æ£€æŸ¥
```bash
curl http://localhost:8000/health
```

### è·å–åµŒå…¥å‘é‡ (OpenAI å…¼å®¹æ ¼å¼)
```bash
curl http://localhost:8000/v1/embeddings \
  -H "Content-Type: application/json" \
  -d '{
    "input": ["Hello, world!", "How are you?"],
    "model": "sentence-transformers/all-MiniLM-L6-v2"
  }'
```

### TEI åŸç”Ÿæ ¼å¼
```bash
curl http://localhost:8000/embed \
  -H "Content-Type: application/json" \
  -d '{"inputs": ["Hello, world!"]}'
```

## å¯ç”¨çš„åŸºç¡€é•œåƒ

| é•œåƒæ ‡ç­¾ | è¯´æ˜ |
|---------|------|
| `ghcr.io/huggingface/text-embeddings-inference:cpu-1.5` | CPU ç‰ˆæœ¬ |
| `ghcr.io/huggingface/text-embeddings-inference:1.5` | CUDA 12 GPU ç‰ˆæœ¬ |
| `ghcr.io/huggingface/text-embeddings-inference:turing-1.5` | CUDA 12 Turing GPU (T4, RTX 2000) |
| `ghcr.io/huggingface/text-embeddings-inference:89-1.5` | CUDA 12 Ampere 86 (A10, A40) |
| `ghcr.io/huggingface/text-embeddings-inference:hopper-1.5` | CUDA 12 Hopper (H100) |

## æ¨èæ¨¡å‹

| æ¨¡å‹ | ç»´åº¦ | è¯´æ˜ |
|------|------|------|
| `sentence-transformers/all-MiniLM-L6-v2` | 384 | è½»é‡çº§ï¼Œé€Ÿåº¦å¿« |
| `BAAI/bge-small-en-v1.5` | 384 | è‹±æ–‡å°æ¨¡å‹ |
| `BAAI/bge-base-en-v1.5` | 768 | è‹±æ–‡åŸºç¡€æ¨¡å‹ |
| `BAAI/bge-large-en-v1.5` | 1024 | è‹±æ–‡å¤§æ¨¡å‹ |
| `BAAI/bge-m3` | 1024 | å¤šè¯­è¨€æ¨¡å‹ |

## å‚è€ƒ

- [TEI GitHub](https://github.com/huggingface/text-embeddings-inference)
- [TEI æ–‡æ¡£](https://huggingface.co/docs/text-embeddings-inference)